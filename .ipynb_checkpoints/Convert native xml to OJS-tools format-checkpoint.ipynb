{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3e26b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "20e7bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = 'test.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "08e547bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python script.py <xml_file>\")\n",
    "        sys.exit(1)  # Exit with an error code\n",
    "\n",
    "    # Retrieve the XML file from command-line arguments\n",
    "    #xml_file = sys.argv[1]\n",
    "    \n",
    "    # Open the XML file with the correct encoding\n",
    "    with open(xml_file, 'rb') as file:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "    \n",
    "    articles = root.findall('.//{http://pkp.sfu.ca}article')\n",
    "    \n",
    "    rows = []\n",
    "    row_id = 0\n",
    "    \n",
    "    for article in articles:\n",
    "        print(row_id)\n",
    "        processed = get_article_info(article, root, row_id)\n",
    "        df = pd.DataFrame.from_dict(processed.to_row())\n",
    "        rows.append(df)\n",
    "        row_id += 1\n",
    "        \n",
    "    df = pd.concat(rows)\n",
    "    \n",
    "    df = df.fillna('')\n",
    "        \n",
    "    df.to_csv('output.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2fd9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Author:\n",
    "    def __init__(self, first_name, last_name):\n",
    "        self.first_name = first_name\n",
    "        self.last_name = last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0430b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def __init__(self, \n",
    "                 article_id, \n",
    "                 title, \n",
    "                 publication, \n",
    "                 abstract, \n",
    "                 base64_file, \n",
    "                 publication_date, \n",
    "                 year, \n",
    "                 issue, \n",
    "                 page_number, \n",
    "                 section_title,\n",
    "                 section_policy,\n",
    "                 section_reference,\n",
    "                 doi,\n",
    "                 authors, \n",
    "                 locale):\n",
    "        \n",
    "        self.article_id = article_id\n",
    "        self.title = title\n",
    "        self.publication = publication\n",
    "        self.abstract = abstract\n",
    "        self.base64_file = base64_file\n",
    "        self.publication_date = publication_date\n",
    "        self.year = year\n",
    "        self.issue = issue\n",
    "        self.page_number = page_number\n",
    "        self.section_title = section_title\n",
    "        self.section_policy = section_policy\n",
    "        self.section_reference = section_reference\n",
    "        self.doi = doi\n",
    "        self.authors = authors\n",
    "        self.locale = locale\n",
    "    \n",
    "    def export_authors(self):\n",
    "        #generate a dict with authors and column titles\n",
    "        amount_of_authors = len(self.authors)\n",
    "        author_id = 0\n",
    "        output = {}\n",
    "        for a in self.authors:\n",
    "            first_name_column = 'author_given_name_' + str(author_id)\n",
    "            last_name_column = 'author_family_name_' + str(author_id)\n",
    "            output[first_name_column] = [a.first_name]\n",
    "            output[last_name_column] = [a.last_name]\n",
    "            author_id += 1\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def to_row(self):\n",
    "        #function that outputs the article as a single row for a df, as a list\n",
    "        output = {'article_id': [self.article_id],\n",
    "                 'title': [self.title],\n",
    "                 'publication': [self.publication],\n",
    "                'abstract': [self.abstract],\n",
    "                'file': [self.base64_file],\n",
    "                'publication_date': [self.publication_date],\n",
    "                'year': [self.year],\n",
    "                'issue': [self.issue],\n",
    "                'page_number': [self.page_number],\n",
    "                'section_title': [self.section_title],\n",
    "                'section_policy': [self.section_policy],\n",
    "                'section_reference': [self.section_reference],\n",
    "                'doi': [self.doi]}\n",
    "        \n",
    "        authors = self.export_authors()\n",
    "        \n",
    "        output = output | authors\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fd4c1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the parent issue of a given article node\n",
    "def find_parent_issue(article_node, root):\n",
    "    for issue in root.findall('.//{http://pkp.sfu.ca}issue'):  # Iterate through all issues\n",
    "        if article_node in issue.findall('.//{http://pkp.sfu.ca}article'):  # Check if the article is in this issue\n",
    "            return issue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c9c6c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(article_node, root, article_id):\n",
    "    \n",
    "    base64_file = 'placeholder'\n",
    "    \n",
    "    publications = article_node.findall('{http://pkp.sfu.ca}publication')\n",
    "    publication = publications[0]\n",
    "    \n",
    "    locale = publication.attrib['locale']\n",
    "    publication_date = publication.attrib['date_published']\n",
    "    section_reference = publication.attrib['section_ref']\n",
    "    \n",
    "    for id_node in publication.findall('{http://pkp.sfu.ca}id'):\n",
    "        if id_node.get('type') == 'doi':  # Check for the 'type' attribute\n",
    "            doi = id_node.text\n",
    "    \n",
    "    for title_node in publication.findall('{http://pkp.sfu.ca}title'):\n",
    "        if title_node.get('locale') == locale:\n",
    "            title = title_node.text\n",
    "    \n",
    "    for abstract_node in publication.findall('{http://pkp.sfu.ca}abstract'):\n",
    "        if abstract_node.get('locale') == locale:\n",
    "            abstract = abstract_node.text\n",
    "    \n",
    "    try:\n",
    "        page_number = publication.findall('{http://pkp.sfu.ca}pages')[0].text\n",
    "    except IndexError:\n",
    "        page_number = ''\n",
    "\n",
    "        \n",
    "    author_list = publication.findall('.//{http://pkp.sfu.ca}author')\n",
    "    authors = []\n",
    "    for a in author_list:\n",
    "        first_name = a.find('{http://pkp.sfu.ca}givenname').text\n",
    "        last_name = a.find('{http://pkp.sfu.ca}familyname').text\n",
    "        authors.append(Author(first_name, last_name))\n",
    "        \n",
    "    parent_issue = find_parent_issue(article_node, root)\n",
    "    issue_identification = parent_issue.find('{http://pkp.sfu.ca}issue_identification')\n",
    "    \n",
    "    issue = issue_identification.find('{http://pkp.sfu.ca}number').text\n",
    "    \n",
    "    try:\n",
    "        year = issue_identification.find('{http://pkp.sfu.ca}year').text\n",
    "    except AttributeError:\n",
    "        year = publication_date[:4]\n",
    "    \n",
    "    for publication_node in issue_identification.findall('{http://pkp.sfu.ca}title'):\n",
    "        if publication_node.get('locale') == locale:\n",
    "            publication = publication_node.text\n",
    "            \n",
    "    section_information = parent_issue.find('{http://pkp.sfu.ca}sections')\n",
    "    for section_node in section_information.findall('{http://pkp.sfu.ca}section'):\n",
    "        if section_node.get('ref') == section_reference:\n",
    "            for section_title_node in section_node.findall('{http://pkp.sfu.ca}title'):\n",
    "                if section_title_node.get('locale') == locale:\n",
    "                    section_title = section_title_node.text\n",
    "            \n",
    "            section_policy = \"\"\n",
    "            for section_policy_node in section_node.findall('{http://pkp.sfu.ca}policy'):\n",
    "                if section_policy_node.get('locale') == locale:\n",
    "                    section_policy = section_policy_node.text\n",
    "                    \n",
    "    return Article(article_id, \n",
    "                 title, \n",
    "                 publication, \n",
    "                 abstract, \n",
    "                 base64_file, \n",
    "                 publication_date,\n",
    "                 year, \n",
    "                 issue, \n",
    "                 page_number, \n",
    "                 section_title,\n",
    "                 section_policy,\n",
    "                 section_reference,\n",
    "                 doi,\n",
    "                 authors, \n",
    "                 locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d174021d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9471cedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6205bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f19010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
