{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4dd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd61c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = 'test.xml'\n",
    "test_galley = 'C:/Users/kayp/GitHub/ojs-tools-martijn/test/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715e4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python script.py <xml_file>\")\n",
    "        sys.exit(1)  # Exit with an error code\n",
    "\n",
    "    # Retrieve the XML file from command-line arguments\n",
    "    #xml_file = sys.argv[1]\n",
    "    \n",
    "    # Open the XML file with the correct encoding\n",
    "    with open(xml_file, 'rb') as file:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "    \n",
    "    articles = root.findall('.//{http://pkp.sfu.ca}article')\n",
    "    \n",
    "    rows = []\n",
    "    row_id = 0\n",
    "    \n",
    "    for article in articles:\n",
    "        #print(row_id)\n",
    "        processed = get_article_info(article, root, row_id)\n",
    "        df = pd.DataFrame.from_dict(processed.to_row())\n",
    "        rows.append(df)\n",
    "        row_id += 1\n",
    "        \n",
    "    df = pd.concat(rows)\n",
    "    \n",
    "    df = df.fillna('')\n",
    "    \n",
    "    df['section_policy'] = df['section_policy'].replace('', 'no section policy').fillna('no section policy')\n",
    "    \n",
    "    df = df.rename(columns={\"article_id\": \"id\"})\n",
    "    \n",
    "    df['volume'] = df['volume'].astype(str)\n",
    "    \n",
    "    \n",
    "    df['issue'] = df['issue'].astype(str)\n",
    "\n",
    "    df.to_csv('output.csv', sep=';', index=False, encoding='utf-8')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc9cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_base64(article_node):\n",
    "    # Find all submission files in the article node\n",
    "    submission_files = article_node.findall('{http://pkp.sfu.ca}submission_file')\n",
    "\n",
    "    # Iterate through each submission file\n",
    "    for submission in submission_files:\n",
    "        # Check each file inside the submission file\n",
    "        for file in submission.findall('{http://pkp.sfu.ca}file'):\n",
    "            # Check if the genre is 'Manuscript'\n",
    "            if submission.get('genre') == 'Manuscript':\n",
    "                # Find the <embed> tag that contains the base64 content\n",
    "                embed = file.find('{http://pkp.sfu.ca}embed')\n",
    "                if embed is not None:\n",
    "                    # Add the base64 content to the list\n",
    "                    base64_contents = embed.text\n",
    "                    \n",
    "    return base64_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4faab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Author:\n",
    "    def __init__(self, first_name, last_name):\n",
    "        self.first_name = first_name\n",
    "        self.last_name = last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a250fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def __init__(self, \n",
    "                 article_id, \n",
    "                 title, \n",
    "                 publication, \n",
    "                 abstract, \n",
    "                 base64_file, \n",
    "                 publication_date, \n",
    "                 year, \n",
    "                 vol,\n",
    "                 issue, \n",
    "                 page_number, \n",
    "                 section_title,\n",
    "                 section_policy,\n",
    "                 section_reference,\n",
    "                 doi,\n",
    "                 authors, \n",
    "                 locale,\n",
    "                 keywords):\n",
    "        \n",
    "        self.article_id = article_id\n",
    "        self.title = title\n",
    "        self.publication = publication\n",
    "        self.abstract = abstract\n",
    "        self.base64_file = base64_file\n",
    "        self.publication_date = publication_date\n",
    "        self.year = year\n",
    "        self.vol = vol\n",
    "        self.issue = issue\n",
    "        self.page_number = page_number\n",
    "        self.section_title = section_title\n",
    "        self.section_policy = section_policy\n",
    "        self.section_reference = section_reference\n",
    "        self.doi = doi\n",
    "        self.authors = authors\n",
    "        self.locale = locale\n",
    "        self.keywords = keywords\n",
    "    \n",
    "    def export_authors(self):\n",
    "        #generate a dict with authors and column titles\n",
    "        amount_of_authors = len(self.authors)\n",
    "        author_id = 0\n",
    "        output = {}\n",
    "        for a in self.authors:\n",
    "            first_name_column = 'author_given_name_' + str(author_id)\n",
    "            last_name_column = 'author_family_name_' + str(author_id)\n",
    "            output[first_name_column] = [a.first_name]\n",
    "            output[last_name_column] = [a.last_name]\n",
    "            author_id += 1\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def to_row(self):\n",
    "        #function that outputs the article as a single row for a df, as a list\n",
    "        output = {'article_id': [self.article_id],\n",
    "                 'title': [self.title],\n",
    "                 'publication': [self.publication],\n",
    "                'abstract': [self.abstract],\n",
    "                'file': [self.base64_file],\n",
    "                'publication_date': [self.publication_date],\n",
    "                'year': [self.year],\n",
    "                'volume': [self.vol],\n",
    "                'issue': [self.issue],\n",
    "                'page_number': [self.page_number],\n",
    "                'section_title': [self.section_title],\n",
    "                'section_policy': [self.section_policy],\n",
    "                'section_reference': [self.section_reference],\n",
    "                'doi': [self.doi],\n",
    "                 'keywords': [self.keywords]}\n",
    "        \n",
    "        authors = self.export_authors()\n",
    "        \n",
    "        output = output | authors\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25254433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the parent issue of a given article node\n",
    "def find_parent_issue(article_node, root):\n",
    "    for issue in root.findall('.//{http://pkp.sfu.ca}issue'):  # Iterate through all issues\n",
    "        if article_node in issue.findall('.//{http://pkp.sfu.ca}article'):  # Check if the article is in this issue\n",
    "            return issue\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(keywords_node):\n",
    "    output = []\n",
    "    for keyword in keywords_node.findall('.//{http://pkp.sfu.ca}keyword'):\n",
    "        output.append(keyword.text)\n",
    "    \n",
    "    output_string = ''\n",
    "    for keyword in output:\n",
    "        output_string = output_string + keyword + '[;sep;]'\n",
    "    \n",
    "    output_string.strip('[;sep;]')\n",
    "    \n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfab776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(article_node, root, article_id):\n",
    "    \n",
    "    #placeholder value\n",
    "    vol = '1'\n",
    "    \n",
    "    base64_file = extract_base64(article_node)\n",
    "    \n",
    "    publications = article_node.findall('{http://pkp.sfu.ca}publication')\n",
    "    publication = publications[0]\n",
    "    \n",
    "    locale = publication.attrib['locale']\n",
    "    publication_date = publication.attrib['date_published']\n",
    "    section_reference = publication.attrib['section_ref']\n",
    "    \n",
    "    keywords = get_keywords(publication.find('{http://pkp.sfu.ca}keywords'))\n",
    "    \n",
    "    for id_node in publication.findall('{http://pkp.sfu.ca}id'):\n",
    "        if id_node.get('type') == 'doi':  # Check for the 'type' attribute\n",
    "            doi = id_node.text\n",
    "    \n",
    "    for title_node in publication.findall('{http://pkp.sfu.ca}title'):\n",
    "        if title_node.get('locale') == locale:\n",
    "            title = title_node.text\n",
    "    \n",
    "    for abstract_node in publication.findall('{http://pkp.sfu.ca}abstract'):\n",
    "        if abstract_node.get('locale') == locale:\n",
    "            abstract = abstract_node.text\n",
    "    \n",
    "    try:\n",
    "        page_number = publication.findall('{http://pkp.sfu.ca}pages')[0].text\n",
    "    except IndexError:\n",
    "        page_number = ''\n",
    "\n",
    "        \n",
    "    author_list = publication.findall('.//{http://pkp.sfu.ca}author')\n",
    "    authors = []\n",
    "    for a in author_list:\n",
    "        first_name = a.find('{http://pkp.sfu.ca}givenname').text\n",
    "        last_name = a.find('{http://pkp.sfu.ca}familyname').text\n",
    "        authors.append(Author(first_name, last_name))\n",
    "        \n",
    "    parent_issue = find_parent_issue(article_node, root)\n",
    "    issue_identification = parent_issue.find('{http://pkp.sfu.ca}issue_identification')\n",
    "    \n",
    "    issue = issue_identification.find('{http://pkp.sfu.ca}number').text\n",
    "    \n",
    "    try:\n",
    "        year = issue_identification.find('{http://pkp.sfu.ca}year').text\n",
    "    except AttributeError:\n",
    "        year = publication_date[:4]\n",
    "    \n",
    "    for publication_node in issue_identification.findall('{http://pkp.sfu.ca}title'):\n",
    "        if publication_node.get('locale') == locale:\n",
    "            publication = publication_node.text\n",
    "            \n",
    "    section_information = parent_issue.find('{http://pkp.sfu.ca}sections')\n",
    "    for section_node in section_information.findall('{http://pkp.sfu.ca}section'):\n",
    "        if section_node.get('ref') == section_reference:\n",
    "            for section_title_node in section_node.findall('{http://pkp.sfu.ca}title'):\n",
    "                if section_title_node.get('locale') == locale:\n",
    "                    section_title = section_title_node.text\n",
    "            \n",
    "            section_policy = \"\"\n",
    "            for section_policy_node in section_node.findall('{http://pkp.sfu.ca}policy'):\n",
    "                if section_policy_node.get('locale') == locale:\n",
    "                    section_policy = section_policy_node.text\n",
    "                    \n",
    "                else:\n",
    "                    section_policy = 'no section policy'\n",
    "                    \n",
    "    return Article(article_id, \n",
    "                 title, \n",
    "                 publication, \n",
    "                 abstract, \n",
    "                 base64_file, \n",
    "                 publication_date,\n",
    "                 year, \n",
    "                 vol,  \n",
    "                 issue, \n",
    "                 page_number, \n",
    "                 section_title,\n",
    "                 section_policy,\n",
    "                 section_reference,\n",
    "                 doi,\n",
    "                 authors, \n",
    "                 locale,\n",
    "                 keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c035841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n",
      "['117' '116']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241d325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57ea8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740bb967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
